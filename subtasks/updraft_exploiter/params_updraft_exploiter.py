import numpy as np


class LearningParameters:
    """ Hyperparameters for training actor-critic model

        Attributes
        ----------

        N_ITERATIONS: float
            total number of episodes to be evaluated

        BATCHSIZE: int
            size of batch (i.e, length of rollout) before policy update

        MINIBATCHSIZE: int
            size of mini-batch for SGD

        K_EPOCH: int
            number of policy updates on single batch

        LEARNING_RATE: float
            learning rate for optimizer

        GAMMA: float
            discount factor for advantage estimation

        LAMBDA: float
            only relevant if GAE is implemented

        EPS_CLIP: float
            PPO clipping value

        SIGMA: float
            std-deviation for exploration (0.1 -> 0.6 deg after scaling)

        AUTO_EXPLORATION: bool
            exploration driven by NN output (self.SIGMA obsolete if true)

        SEED: None
            manual specification of random seed (Fabian: 42)
    """
    def __init__(self):
        self.N_ITERATIONS = 2e3
        self.BATCHSIZE = 4096
        self.MINIBATCHSIZE = 64
        self.K_EPOCH = 10
        self.LEARNING_RATE = 1e-5
        self.GAMMA = 0.99
        # self.LAMBDA = 0.96
        self.EPS_CLIP = 0.2
        self.SIGMA = .2
        self.AUTO_EXPLORATION = False
        self.SEED = None


class ModelParameters:
    """ Parameters which describe ANN architecture

       Attributes
       ----------

       DIM_IN: int
           Dimension of input layer (observation-space)

       DIM_OUT: int
           Dimension of output layer (action-space). For decision maker: prob. for subtask

       DIM_HIDDEN: int
           Dimension of hidden layer

       DIM_LSTM: int
           Dimension of LSTM layer
       """
    def __init__(self):
        self.DIM_IN = 2
        self.DIM_OUT = 2
        self.DIM_HIDDEN = 32
        self.DIM_LSTM = 32


class AgentParameters:
    """ Parameters for initializing and simulation agent (glider)

        Attributes
        ----------

        TIMESTEP_CTRL: float
            Control update time-step [s]

        INITIAL_SPACE: ndarray
            initial state space [MIN MAX]

        ACTION_SPACE: ndarray
            bank angle and AoA constraint to [MIN MAX]  (deg)

        DISTANCE_MAX: float
            maximum horizontal distance allowed from origin (ensures that a safety pilot could interact)

        HEIGHT_MAX: int
            maximum height allowed
        """
    def __init__(self):

        self.TIMESTEP_CTRL = 1.0
        self.INITIAL_SPACE = np.array([[-500, 500],
                                       [-500, 500],
                                       [-300, -100],
                                       [-10, 10],
                                       [-10, 10],
                                       [0.5, 1.5]])

        self.ACTION_SPACE = np.array([[-45, 45],
                                      [0, 12]])

        self.DISTANCE_MAX = 1e3
        self.HEIGHT_MAX = 500


class LoggingParameters:
    """ Intervals for saving and logging

        Attributes
        ----------

        PRINT_INTERVAL: int
            Interval wrt # epi to print score and save avg. return to file
        SAVE_INTERVAL: int
            Interval wrt # epi to save actor/critic net and make a plot
        """
    
    def __init__(self):
        self.PRINT_INTERVAL = 10  # interval wrt # epi to print score and save avg. return to file
        self.SAVE_INTERVAL = 250  # interval wrt # epi to save actor/critic net and make a plot
